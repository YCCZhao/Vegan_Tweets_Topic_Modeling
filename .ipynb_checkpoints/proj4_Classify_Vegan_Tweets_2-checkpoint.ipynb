{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "import re\n",
    "from nltk import ngrams\n",
    "from string import punctuation\n",
    "from bson.son import SON\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(port=27017)\n",
    "db = client.tweet_on_vegan\n",
    "popular_tweets = db.streaming_tweets\n",
    "texts = popular_tweets.find({}, {'_id':1,\"id\":1,\"text\":1,'is_retweet':1}).skip(400000).limit(100)\n",
    "for text in texts:\n",
    "    pass\n",
    "    #print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(port=27017)\n",
    "db = client.tweet_on_vegan\n",
    "popular_tweets = db.streaming_tweets\n",
    "texts = popular_tweets.find({'lang':'en'}, \n",
    "                            {'_id':0,\"text\":1})\n",
    "tweets = [text['text'] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22554</th>\n",
       "      <td>Please RT? #vegetarian #vegan #healthyfood #re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30641</th>\n",
       "      <td>Oh yes #Dairy farmers care.\\nThey care about p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135251</th>\n",
       "      <td>RT @BigHospitality: High profile US vegan rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372181</th>\n",
       "      <td>RT @janelleshakur: asap ferg is vegan NONE OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253975</th>\n",
       "      <td>RT @taylorndean: That fox looks like it’s on h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets\n",
       "22554   Please RT? #vegetarian #vegan #healthyfood #re...\n",
       "30641   Oh yes #Dairy farmers care.\\nThey care about p...\n",
       "135251  RT @BigHospitality: High profile US vegan rest...\n",
       "372181  RT @janelleshakur: asap ferg is vegan NONE OF ...\n",
       "253975  RT @taylorndean: That fox looks like it’s on h..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mvp_tweets = pd.DataFrame(tweets, columns=['tweets'])\n",
    "mvp_tweets.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "* Remove urls\n",
    "* Remove user names\n",
    "* Remove line breaks\n",
    "* Group tweets and count retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142411</th>\n",
       "      <td>Looking for healthy energy Stop by  table to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132012</th>\n",
       "      <td>Retweeted Vegan Paradise   My food is grown no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88919</th>\n",
       "      <td>Sis is vegan and thicc my inspiration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146767</th>\n",
       "      <td>Nutrition Guidelines for Children Should Inclu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197</th>\n",
       "      <td>Please RT recipes food cooking delicious cook ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  retweets\n",
       "142411  Looking for healthy energy Stop by  table to t...         1\n",
       "132012  Retweeted Vegan Paradise   My food is grown no...         1\n",
       "88919               Sis is vegan and thicc my inspiration         1\n",
       "146767  Nutrition Guidelines for Children Should Inclu...         1\n",
       "16197   Please RT recipes food cooking delicious cook ...         2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/a/13752628/6762004\n",
    "RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "def clean_tweet(x):\n",
    "    x = x.strip()\n",
    "    x = RE_EMOJI.sub(r'', x)\n",
    "    x = re.sub(r'http\\S+', '', x, flags=re.MULTILINE)\n",
    "    x = re.sub(r'RT\\s@\\S+', '', x, flags=re.MULTILINE)\n",
    "    x = re.sub(r'@\\S+', '', x, flags=re.MULTILINE)\n",
    "    x = re.sub(r'\\n', ' ', x, flags=re.MULTILINE)\n",
    "    return (''.join(c for c in x if c not in punctuation)).strip()\n",
    "\n",
    "mvp_tweets.tweets = mvp_tweets.tweets.apply(clean_tweet)\n",
    "\n",
    "mvp_tweets = (pd.DataFrame(mvp_tweets.tweets.value_counts())\n",
    "              .reset_index()\n",
    "              .rename(columns={'tweets':'retweets', 'index': 'text'}))\n",
    "mvp_tweets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148187 entries, 0 to 148186\n",
      "Data columns (total 2 columns):\n",
      "text        148187 non-null object\n",
      "retweets    148187 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to be a vegan but I’m hungry</td>\n",
       "      <td>15243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone please save this fox from this crazy v...</td>\n",
       "      <td>14820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are vegan and don’t want to feed carniv...</td>\n",
       "      <td>10214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That fox looks like it’s on his death bed A ca...</td>\n",
       "      <td>7912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y’all heard Beyoncé it’s VEGAN TIME</td>\n",
       "      <td>6003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Me I could never be a vegan  Beyoncé Vegan tim...</td>\n",
       "      <td>5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes im vegan yes i eat meat we exist</td>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BREAKING NEWS Mariah Carey has officially beco...</td>\n",
       "      <td>4014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>can people like NOT debate whether or not you ...</td>\n",
       "      <td>3859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>are you going to be okay</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  retweets\n",
       "0                I want to be a vegan but I’m hungry     15243\n",
       "1  someone please save this fox from this crazy v...     14820\n",
       "2  If you are vegan and don’t want to feed carniv...     10214\n",
       "3  That fox looks like it’s on his death bed A ca...      7912\n",
       "4                Y’all heard Beyoncé it’s VEGAN TIME      6003\n",
       "5  Me I could never be a vegan  Beyoncé Vegan tim...      5062\n",
       "6               yes im vegan yes i eat meat we exist      4418\n",
       "7  BREAKING NEWS Mariah Carey has officially beco...      4014\n",
       "8  can people like NOT debate whether or not you ...      3859\n",
       "9                           are you going to be okay      3495"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "mvp_tweets.info()\n",
    "mvp_tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stop words\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "my_stop_words = [u'vegan', u'amp', \n",
    "                 u\"think\", u\"thinks\", u\"thought\",\n",
    "                 u\"okay\", u\"Okay\", u\"OKAY\",\n",
    "                 u\"want\", u\"wants\",\n",
    "                 u\"like\",\n",
    "                 u\"amp\", u\"vegan\", u\"Vegan\", u\"VEGAN\"]\n",
    "for stopword in my_stop_words:\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    lexeme.is_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "from spacy.lang.en.stop_words import STOP_WORDS  # import stop words from language data\n",
    "stop_words = STOP_WORDS | set(my_stop_words)\n",
    "stop_words_getter = lambda token: token.is_stop or token.lower_ in stop_words or token.lemma_ in stop_words\n",
    "Token.set_extension('is_stop', getter=stop_words_getter)  # set attribute with getter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n"
     ]
    }
   ],
   "source": [
    "# we add some words to the stop word list\n",
    "tweets_spacy = []\n",
    "\n",
    "for i, tweet in enumerate(mvp_tweets.text):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    tweet_tokenized = []\n",
    "    doc = nlp(tweet)\n",
    "    for token in doc:\n",
    "    # if it's not a stop word or punctuation mark, add it to our article!\n",
    "        if not token.is_stop and not token.is_punct \\\n",
    "        and not token.like_num and not token.pos_ in ['SYM', 'SPACE']\\\n",
    "        and not token.lemma_ == '-PRON-' and token.__len__() >= 2:\n",
    "            # we add the lematized version of the word\n",
    "            tweet_tokenized.append(token.lemma_)\n",
    "    tweets_spacy.append(tweet_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_twograms = []\n",
    "for i in range(len(tweets_spacy)):\n",
    "    twograms = ngrams(tweets_spacy[i], 2)\n",
    "    temp = []\n",
    "    for grams in twograms:\n",
    "        #pass\n",
    "        temp.append(' '.join(grams))\n",
    "        \n",
    "    tweets_twograms.append(temp+tweets_spacy[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148187"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_twograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for ent in tweet_tokenized.ents:\n",
    "#    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for noun_chunks in doc.noun_chunks:\n",
    "#    print(noun_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "* TF-IDF (sklearn)\n",
    "* LSA (gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from nltk.tokenize import word_tokenize, wordpunct_tokenize, WhitespaceTokenizer\n",
    "#from nltk.chunk import ne_chunk\n",
    "#from nltk.tag import pos_tag\n",
    "\n",
    "# Text with some entities\n",
    "#sample_tweet = np.array(foo.text)\n",
    "#for t in sample_tweet[:5]:\n",
    "#    tokens = pos_tag(word_tokenize(t))\n",
    "#    entities = ne_chunk(tokens)\n",
    "\n",
    "#foo.text.apply(lambda x: pos_tag(word_tokenize(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union([u'vegan', u'amp', \n",
    "                 u\"think\", u\"thinks\", u\"thought\",\n",
    "                 u\"okay\", u\"Okay\", u\"OKAY\",\n",
    "                 u\"want\", u\"wants\"\n",
    "                 u\"amp\", u\"vegan\", u\"Vegan\", u\"VEGAN\",\n",
    "                 u\"like\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# This uses WordNet (huge lexical database of English words)\n",
    "stemmer = LancasterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "\n",
    "# Create a vectorizer object to generate term document counts\n",
    "# Note all the parameters we can use, let's play!\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False,\n",
    "                        stop_words = my_stop_words, \n",
    "                        min_df=100, max_df=0.8, ngram_range=(1,2))\n",
    "                        #analyzer=stemmed_words)\n",
    "#tokenizer=lambda i:i, lowercase=False,    \n",
    "\n",
    "# Get the vectors\n",
    "sample_tweet_train = tfidf.fit_transform(tweets_twograms)\n",
    "# Store them in a Pandas DataFrame\n",
    "#sample_tweet_train_df = pd.DataFrame(sample_tweet_train.todense(), \n",
    "                           #columns=[tfidf.get_feature_names()])\n",
    "#sample_tweet_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA (gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from gensim import corpora, models, similarities, matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "# Need to transpose it for gensim which wants \n",
    "# terms by docs instead of docs by terms\n",
    "tfidf_corpus = matutils.Sparse2Corpus(sample_tweet_train.transpose())\n",
    "\n",
    "# Row indices\n",
    "id2word = dict((v, k) for k, v in tfidf.vocabulary_.items())\n",
    "\n",
    "# This is a hack for Python 3!\n",
    "id2word = corpora.Dictionary.from_corpus(tfidf_corpus, \n",
    "                                         id2word=id2word)\n",
    "\n",
    "# Build an LSI space from the input TFIDF matrix, mapping of row id to word, and num_topics\n",
    "# num_topics is the number of dimensions to reduce to after the SVD\n",
    "# Analagous to \"fit\" in sklearn, it primes an LSI space\n",
    "lsi = models.LsiModel(tfidf_corpus, id2word=id2word, num_topics=100)\n",
    "\n",
    "# Retrieve vectors for the original tfidf corpus in the LSI space (\"transform\" in sklearn)\n",
    "lsi_corpus = lsi[tfidf_corpus]\n",
    "\n",
    "# Dump the resulting document vectors into a list so we can take a look\n",
    "doc_vecs = [doc for doc in lsi_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an index transformer that calculates similarity based on \n",
    "# our space\n",
    "index = similarities.MatrixSimilarity(doc_vecs, \n",
    "                                      num_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the sorted list of cosine similarities to the first document\n",
    "sims = sorted(enumerate(index[doc_vecs[7]]), key=lambda item: -item[1])\n",
    "\n",
    "#similar_tweet = {}\n",
    "similar_tweet = []\n",
    "count = 0\n",
    "for tweet, similarity in sims:\n",
    "    if similarity >= 0.8:\n",
    "        #pass\n",
    "        count += 1\n",
    "        print(mvp_tweets.loc[tweet, 'text'])\n",
    "        #similar_tweet.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the gensim-style corpus vecs to a numpy array for sklearn manipulations\n",
    "ng_lsi = matutils.corpus2dense(lsi_corpus, num_terms=100).transpose()\n",
    "ng_lsi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "ng_lsi_standard = scaler.fit_transform(ng_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,52,5):\n",
    "    print(k)\n",
    "    #km = KMeans(n_clusters=k, random_state=1)\n",
    "    km = MiniBatchKMeans(n_clusters=k)\n",
    "    km.fit(ng_lsi_standard)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(silhouette_score(ng_lsi_standard, labels, metric='euclidean'))\n",
    "    SSEs.append(km.inertia_) \n",
    "    \n",
    "   # print(Sil_coefs)\n",
    "   # print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True, dpi=200)\n",
    "k_clusters = range(2,52,5)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "\n",
    "# plot here on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create KMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=22)\n",
    "\n",
    "# Cluster\n",
    "ng_lsi_clusters = kmeans.fit_predict(ng_lsi_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(ng_lsi_clusters, bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, tweet in enumerate(mvp_tweets.text):\n",
    "    if ng_lsi_clusters[i] == 3:\n",
    "        print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 2\n",
    "\n",
    "* CountVecorizer\n",
    "* LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# This uses WordNet (huge lexical database of English words)\n",
    "stemmer = LancasterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda i:i, lowercase=False,\n",
    "                                   stop_words = my_stop_words, \n",
    "                                   min_df=100, max_df=0.8)\n",
    "                                  #analyzer=stemmed_words)\n",
    "\n",
    "# Create a vectorizer object to generate term document counts\n",
    "# Note all the parameters we can use, let's play!\n",
    "#cv = CountVectorizer(token_pattern='[a-z][a-z]+',\n",
    "#                     stop_words = 'english')\n",
    "#tokenizer=lambda i:i, lowercase=False,\n",
    "#token_pattern='[a-z][a-z]+', ngram_range=(1,2),\n",
    "# Get the vectors\n",
    "count_vectorizer.fit(tweets_twograms)\n",
    "counts = count_vectorizer.transform(tweets_twograms).transpose()\n",
    "# Store them in a Pandas DataFrame\n",
    "#sample_tweet_train_df = pd.DataFrame(sample_tweet_train.todense(), columns=[stem_vectorizer.get_feature_names()])\n",
    "#ng_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words = counts.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148187, 2218)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words = np.sum(bag_of_words, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = list(zip(count_vectorizer.get_feature_names(), np.squeeze(np.asarray(bag_of_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1st', 192),\n",
       " ('able', 406),\n",
       " ('abs', 197),\n",
       " ('abs exercise', 164),\n",
       " ('absolute', 107),\n",
       " ('absolutely', 423),\n",
       " ('abuse', 567),\n",
       " ('accept', 129),\n",
       " ('accidentally', 150),\n",
       " ('accord', 136),\n",
       " ('account', 261),\n",
       " ('achieve', 217),\n",
       " ('acid', 135),\n",
       " ('acne', 112),\n",
       " ('act', 287),\n",
       " ('action', 155),\n",
       " ('activism', 167),\n",
       " ('activist', 335),\n",
       " ('actual', 210),\n",
       " ('actually', 1558),\n",
       " ('ad', 342),\n",
       " ('add', 1834),\n",
       " ('add closet', 195),\n",
       " ('add video', 521),\n",
       " ('addition', 101),\n",
       " ('ado1305', 214),\n",
       " ('ado1305 save', 143),\n",
       " ('adopt', 201),\n",
       " ('adventure', 129),\n",
       " ('advice', 220),\n",
       " ('advocate', 147),\n",
       " ('af', 289),\n",
       " ('affect', 102),\n",
       " ('afford', 224),\n",
       " ('affordable', 109),\n",
       " ('afternoon', 165),\n",
       " ('age', 229),\n",
       " ('ago', 487),\n",
       " ('agree', 482),\n",
       " ('agriculture', 185),\n",
       " ('ahead', 261),\n",
       " ('air', 391),\n",
       " ('aka', 130),\n",
       " ('alcohol', 123),\n",
       " ('alert', 101),\n",
       " ('alfredo', 147),\n",
       " ('alive', 325),\n",
       " ('alive say', 131),\n",
       " ('allergic', 134),\n",
       " ('allergy', 187),\n",
       " ('allnatural', 111),\n",
       " ('allow', 249),\n",
       " ('almond', 894),\n",
       " ('almond milk', 389),\n",
       " ('alternative', 724),\n",
       " ('amazing', 1762),\n",
       " ('amazon', 289),\n",
       " ('america', 156),\n",
       " ('american', 157),\n",
       " ('and its', 103),\n",
       " ('and not', 103),\n",
       " ('angry', 202),\n",
       " ('animal', 8128),\n",
       " ('animal abuse', 217),\n",
       " ('animal agriculture', 127),\n",
       " ('animal cruelty', 224),\n",
       " ('animal eat', 143),\n",
       " ('animal not', 238),\n",
       " ('animal product', 558),\n",
       " ('animal right', 199),\n",
       " ('animalcruelty', 150),\n",
       " ('animalright', 293),\n",
       " ('animalrights', 410),\n",
       " ('animals', 195),\n",
       " ('announce', 335),\n",
       " ('annoying', 360),\n",
       " ('answer', 320),\n",
       " ('anti', 122),\n",
       " ('anymore', 316),\n",
       " ('app', 238),\n",
       " ('apparently', 183),\n",
       " ('apple', 489),\n",
       " ('apply', 147),\n",
       " ('appreciate', 201),\n",
       " ('approve', 117),\n",
       " ('april', 210),\n",
       " ('aqu143', 302),\n",
       " ('aqu143 save', 151),\n",
       " ('area', 211),\n",
       " ('argue', 153),\n",
       " ('argument', 261),\n",
       " ('arrive', 166),\n",
       " ('art', 455),\n",
       " ('article', 381),\n",
       " ('artist', 242),\n",
       " ('asian', 143),\n",
       " ('ask', 1462),\n",
       " ('asparagus', 126),\n",
       " ('ass', 955),\n",
       " ('asshole', 105),\n",
       " ('assume', 178),\n",
       " ('athlete', 257),\n",
       " ('attack', 312),\n",
       " ('attempt', 205),\n",
       " ('attention', 133),\n",
       " ('australia', 115),\n",
       " ('author', 188),\n",
       " ('available', 1150),\n",
       " ('avocado', 822),\n",
       " ('avoid', 259),\n",
       " ('award', 140),\n",
       " ('aware', 147),\n",
       " ('away', 696),\n",
       " ('awesome', 697),\n",
       " ('awful', 117),\n",
       " ('b12', 205),\n",
       " ('babe', 121),\n",
       " ('baby', 896),\n",
       " ('bacon', 991),\n",
       " ('bad', 1555),\n",
       " ('bag', 669),\n",
       " ('bagel', 152),\n",
       " ('baileys', 162),\n",
       " ('bake', 871),\n",
       " ('baked', 352),\n",
       " ('bakery', 251),\n",
       " ('baking', 135),\n",
       " ('balance', 213),\n",
       " ('ball', 182),\n",
       " ('ban', 171),\n",
       " ('banana', 908),\n",
       " ('banana bread', 154),\n",
       " ('bar', 946),\n",
       " ('bars', 218),\n",
       " ('base', 1513),\n",
       " ('base diet', 261),\n",
       " ('based', 220),\n",
       " ('basic', 120),\n",
       " ('basically', 246),\n",
       " ('basil', 150),\n",
       " ('batch', 104),\n",
       " ('bath', 264),\n",
       " ('bbq', 547),\n",
       " ('bc', 926),\n",
       " ('be be', 195),\n",
       " ('be eat', 311),\n",
       " ('be go', 1072),\n",
       " ('be good', 177),\n",
       " ('be happy', 109),\n",
       " ('be look', 145),\n",
       " ('be make', 113),\n",
       " ('be not', 1001),\n",
       " ('be sorry', 113),\n",
       " ('be sure', 171),\n",
       " ('be try', 230),\n",
       " ('be vegetarian', 213),\n",
       " ('beach', 128),\n",
       " ('bean', 1306),\n",
       " ('beans', 175),\n",
       " ('bear', 236),\n",
       " ('beastfromtheeast', 152),\n",
       " ('beat', 253),\n",
       " ('beautiful', 724),\n",
       " ('beauty', 1289),\n",
       " ('beauty bodybuilding', 294),\n",
       " ('bed', 166),\n",
       " ('bee', 147),\n",
       " ('beef', 702),\n",
       " ('beer', 402),\n",
       " ('beet', 166),\n",
       " ('begin', 187),\n",
       " ('belief', 177),\n",
       " ('believe', 847),\n",
       " ('bell', 174),\n",
       " ('belly', 102),\n",
       " ('ben', 164),\n",
       " ('benefit', 605),\n",
       " ('berry', 255),\n",
       " ('best', 486),\n",
       " ('bet', 215),\n",
       " ('better', 558),\n",
       " ('bey', 463),\n",
       " ('beyonce', 1258),\n",
       " ('beyonce go', 176),\n",
       " ('beyonce say', 122),\n",
       " ('beyoncé', 2327),\n",
       " ('beyoncé be', 149),\n",
       " ('beyoncé go', 269),\n",
       " ('beyoncé say', 244),\n",
       " ('beyoncé ’s', 116),\n",
       " ('big', 1170),\n",
       " ('bio', 388),\n",
       " ('bird', 149),\n",
       " ('birthday', 525),\n",
       " ('biscuit', 145),\n",
       " ('bit', 592),\n",
       " ('bitch', 1257),\n",
       " ('bite', 248),\n",
       " ('black', 1175),\n",
       " ('black bean', 310),\n",
       " ('blend', 180),\n",
       " ('bless', 153),\n",
       " ('block', 207),\n",
       " ('blog', 1170),\n",
       " ('blog blogger', 172),\n",
       " ('blog post', 206),\n",
       " ('blogger', 574),\n",
       " ('blogger stretch', 160),\n",
       " ('blogger yoga', 164),\n",
       " ('blood', 332),\n",
       " ('bloody', 103),\n",
       " ('blow', 147),\n",
       " ('blue', 295),\n",
       " ('blueberry', 406),\n",
       " ('board', 115),\n",
       " ('body', 1334),\n",
       " ('bodybuilding', 459),\n",
       " ('bodybuilding muscle', 255),\n",
       " ('bomb', 384),\n",
       " ('bone', 132),\n",
       " ('book', 858),\n",
       " ('boost', 161),\n",
       " ('boot', 134),\n",
       " ('bother', 121),\n",
       " ('bottle', 163),\n",
       " ('bout', 183),\n",
       " ('bowl', 858),\n",
       " ('box', 473),\n",
       " ('boy', 353),\n",
       " ('boyfriend', 117),\n",
       " ('brain', 172),\n",
       " ('brand', 855),\n",
       " ('brand new', 132),\n",
       " ('bread', 969),\n",
       " ('break', 623),\n",
       " ('break news', 159),\n",
       " ('breakfast', 1814),\n",
       " ('breathe', 188),\n",
       " ('brighton', 185),\n",
       " ('brilliant', 101),\n",
       " ('bring', 871),\n",
       " ('british', 126),\n",
       " ('britishpieweek', 102),\n",
       " ('bro', 204),\n",
       " ('broccoli', 390),\n",
       " ('brooklyn', 140),\n",
       " ('brother', 164),\n",
       " ('brown', 317),\n",
       " ('brown rice', 128),\n",
       " ('brownie', 484),\n",
       " ('brownies', 122),\n",
       " ('bruh', 102),\n",
       " ('brunch', 395),\n",
       " ('brush', 145),\n",
       " ('btw', 176),\n",
       " ('budget', 147),\n",
       " ('buffalo', 224),\n",
       " ('build', 182),\n",
       " ('bullshit', 190),\n",
       " ('bun', 225),\n",
       " ('bunch', 186),\n",
       " ('bunny', 160),\n",
       " ('burger', 2183),\n",
       " ('burgers', 136),\n",
       " ('burn', 128),\n",
       " ('burrito', 297),\n",
       " ('business', 556),\n",
       " ('busy', 157),\n",
       " ('but not', 117),\n",
       " ('butter', 1376),\n",
       " ('butternut', 193),\n",
       " ('butternut squash', 157),\n",
       " ('buy', 1872),\n",
       " ('bye', 135),\n",
       " ('cabbage', 181),\n",
       " ('cacao', 120),\n",
       " ('cafe', 684),\n",
       " ('cake', 2074),\n",
       " ('calcium', 115),\n",
       " ('calf', 204),\n",
       " ('california', 188),\n",
       " ('calm', 123),\n",
       " ('calorie', 248),\n",
       " ('campaign', 155),\n",
       " ('can not', 397),\n",
       " ('canada', 152),\n",
       " ('cancer', 495),\n",
       " ('candle', 262),\n",
       " ('candy', 194),\n",
       " ('cannabis', 152),\n",
       " ('car', 225),\n",
       " ('caramel', 300),\n",
       " ('carb', 339),\n",
       " ('card', 165),\n",
       " ('care', 1243),\n",
       " ('care animal', 153),\n",
       " ('carnivore', 482),\n",
       " ('carnivorous', 321),\n",
       " ('carnivorous animal', 146),\n",
       " ('carrot', 665),\n",
       " ('carrot cake', 135),\n",
       " ('carry', 146),\n",
       " ('case', 419),\n",
       " ('cashew', 417),\n",
       " ('cat', 1196),\n",
       " ('catch', 211),\n",
       " ('cater', 104),\n",
       " ('catering', 108),\n",
       " ('cauliflower', 626),\n",
       " ('cause', 306),\n",
       " ('cbd', 138),\n",
       " ('celebrate', 465),\n",
       " ('celebrity', 146),\n",
       " ('cereal', 140),\n",
       " ('certain', 198),\n",
       " ('chain', 187),\n",
       " ('challenge', 659),\n",
       " ('chance', 404),\n",
       " ('chance win', 148),\n",
       " ('change', 1384),\n",
       " ('channel', 177),\n",
       " ('chat', 182),\n",
       " ('cheap', 526),\n",
       " ('cheat', 104),\n",
       " ('check', 2106),\n",
       " ('checkout', 179),\n",
       " ('checkout get', 138),\n",
       " ('cheddar', 147),\n",
       " ('cheese', 4171),\n",
       " ('cheesecake', 398),\n",
       " ('cheesy', 168),\n",
       " ('chef', 957),\n",
       " ('chef dinnertime', 292),\n",
       " ('chemical', 112),\n",
       " ('cherry', 202),\n",
       " ('chia', 284),\n",
       " ('chia seed', 104),\n",
       " ('chicago', 120),\n",
       " ('chick', 147),\n",
       " ('chicken', 2364),\n",
       " ('chicken nugget', 140),\n",
       " ('chickpea', 596),\n",
       " ('child', 434),\n",
       " ('chili', 511),\n",
       " ('chill', 177),\n",
       " ('chilli', 312),\n",
       " ('china', 138),\n",
       " ('chinese', 156),\n",
       " ('chip', 802),\n",
       " ('chip cookie', 122),\n",
       " ('chipotle', 160),\n",
       " ('chloe', 167),\n",
       " ('choc', 120),\n",
       " ('chocolate', 3244),\n",
       " ('chocolate cake', 210),\n",
       " ('chocolate chip', 323),\n",
       " ('choice', 960),\n",
       " ('cholesterol', 119),\n",
       " ('choose', 838),\n",
       " ('chop', 117),\n",
       " ('christmas', 123),\n",
       " ('cinnamon', 431),\n",
       " ('cinnamon roll', 116),\n",
       " ('city', 371),\n",
       " ('claim', 418),\n",
       " ('class', 409),\n",
       " ('classic', 251),\n",
       " ('clean', 454),\n",
       " ('cleaneat', 195),\n",
       " ('cleanse', 146),\n",
       " ('clear', 240),\n",
       " ('clearly', 186),\n",
       " ('click', 332),\n",
       " ('click link', 146),\n",
       " ('climate', 183),\n",
       " ('climate change', 117),\n",
       " ('climatechange', 151),\n",
       " ('close', 366),\n",
       " ('closet', 212),\n",
       " ('closet poshmark', 195),\n",
       " ('clothing', 141),\n",
       " ('club', 200),\n",
       " ('coachella', 891),\n",
       " ('coat', 107),\n",
       " ('cocktail', 112),\n",
       " ('coconut', 1271),\n",
       " ('coconut milk', 161),\n",
       " ('coconut oil', 124),\n",
       " ('code', 846),\n",
       " ('code ado1305', 214),\n",
       " ('code aqu143', 302),\n",
       " ('coffee', 936),\n",
       " ('cold', 572),\n",
       " ('collection', 244),\n",
       " ('college', 156),\n",
       " ('color', 246),\n",
       " ('colour', 123),\n",
       " ('come', 3375),\n",
       " ('come soon', 145),\n",
       " ('comfort', 304),\n",
       " ('comfort food', 179),\n",
       " ('comment', 382),\n",
       " ('commit', 121),\n",
       " ('common', 176),\n",
       " ('community', 483),\n",
       " ('company', 505),\n",
       " ('compare', 144),\n",
       " ('compassion', 429),\n",
       " ('compassion animal', 100),\n",
       " ('compassionate', 120),\n",
       " ('competition', 275),\n",
       " ('complain', 133),\n",
       " ('complete', 283),\n",
       " ('completely', 430),\n",
       " ('condition', 147),\n",
       " ('confirm', 121),\n",
       " ('confused', 112),\n",
       " ('conscious', 128),\n",
       " ('consider', 667),\n",
       " ('consider go', 131),\n",
       " ('consume', 354),\n",
       " ('consumer', 117),\n",
       " ('consumption', 224),\n",
       " ('contact', 101),\n",
       " ('contain', 332),\n",
       " ('continue', 305),\n",
       " ('contribute', 161),\n",
       " ('control', 189),\n",
       " ('conversation', 144),\n",
       " ('convert', 129),\n",
       " ('convince', 192),\n",
       " ('cook', 2073),\n",
       " ('cook delicious', 277),\n",
       " ('cook recipe', 270),\n",
       " ('cookbook', 539),\n",
       " ('cooker', 116),\n",
       " ('cookie', 1249),\n",
       " ('cookie dough', 139),\n",
       " ('cookies', 389),\n",
       " ('cooking', 1484),\n",
       " ('cooking maincuisine', 292),\n",
       " ('cooking recipe', 315),\n",
       " ('cool', 577),\n",
       " ('copy', 180),\n",
       " ('corn', 335),\n",
       " ('correct', 104),\n",
       " ('cosmetic', 210),\n",
       " ('cost', 221),\n",
       " ('count', 181),\n",
       " ('country', 299),\n",
       " ('couple', 428),\n",
       " ('coupon', 267),\n",
       " ('course', 534),\n",
       " ('cousin', 115),\n",
       " ('cover', 325),\n",
       " ('cow', 1062),\n",
       " ('cow milk', 167),\n",
       " ('coworker', 109),\n",
       " ('crack', 120),\n",
       " ('cracker', 108),\n",
       " ('cranberry', 126),\n",
       " ('crap', 115),\n",
       " ('crave', 276),\n",
       " ('craving', 120),\n",
       " ('crazy', 395),\n",
       " ('cream', 1938),\n",
       " ('cream cheese', 169),\n",
       " ('creamy', 651),\n",
       " ('create', 550),\n",
       " ('creative', 135),\n",
       " ('creature', 137),\n",
       " ('creme', 105),\n",
       " ('crisp', 106),\n",
       " ('crispy', 258),\n",
       " ('cross', 143),\n",
       " ('cruel', 221),\n",
       " ('cruelty', 1410),\n",
       " ('cruelty free', 835),\n",
       " ('crueltyfree', 1957),\n",
       " ('crunchy', 104),\n",
       " ('crust', 150),\n",
       " ('cucumber', 182),\n",
       " ('cuisine', 453),\n",
       " ('cuisine food', 292),\n",
       " ('culture', 225),\n",
       " ('cup', 355),\n",
       " ('cupcake', 371),\n",
       " ('cupcakes', 113),\n",
       " ('cure', 224),\n",
       " ('curious', 159),\n",
       " ('current', 110),\n",
       " ('currently', 238),\n",
       " ('curry', 838),\n",
       " ('customer', 271),\n",
       " ('cut', 589),\n",
       " ('cute', 451),\n",
       " ('cuz', 266),\n",
       " ('dad', 221),\n",
       " ('daily', 999),\n",
       " ('daily thank', 401),\n",
       " ('dairy', 2448),\n",
       " ('dairy free', 364),\n",
       " ('dairy industry', 178),\n",
       " ('dairy milk', 174),\n",
       " ('dairyfree', 1455),\n",
       " ('dairyfree glutenfree', 115),\n",
       " ('dairyisscary', 114),\n",
       " ('damn', 696),\n",
       " ('dance', 129),\n",
       " ('dark', 330),\n",
       " ('dark chocolate', 196),\n",
       " ('date', 542),\n",
       " ('daughter', 182),\n",
       " ('david', 107),\n",
       " ('day', 5850),\n",
       " ('dead', 367),\n",
       " ('deal', 376),\n",
       " ('dear', 147),\n",
       " ('death', 396),\n",
       " ('debate', 240),\n",
       " ('decent', 126),\n",
       " ('decide', 500),\n",
       " ('decision', 275),\n",
       " ('deep', 229),\n",
       " ('definitely', 583),\n",
       " ('delicious', 3437),\n",
       " ('delicious cook', 261),\n",
       " ('delicious food', 115),\n",
       " ('delight', 125),\n",
       " ('delish', 159),\n",
       " ('deliver', 173),\n",
       " ('delivery', 228),\n",
       " ('demand', 237),\n",
       " ('depend', 141),\n",
       " ('desert', 107),\n",
       " ('deserve', 249),\n",
       " ('design', 239),\n",
       " ('dessert', 715),\n",
       " ('destroy', 134),\n",
       " ('detox', 260),\n",
       " ('diabetes', 174),\n",
       " ('dick', 256),\n",
       " ('die', 910),\n",
       " ('diet', 6853),\n",
       " ('diet motivation', 103),\n",
       " ('diet not', 156),\n",
       " ('dietary', 210),\n",
       " ('diets', 100),\n",
       " ('difference', 418),\n",
       " ('different', 652),\n",
       " ('difficult', 202),\n",
       " ('dining', 133),\n",
       " ('dinner', 1716),\n",
       " ('dinner tonight', 134),\n",
       " ('dinnertime', 312),\n",
       " ('dinnertime foodchannel', 292),\n",
       " ('dip', 296),\n",
       " ('discount', 686),\n",
       " ('discount save', 112),\n",
       " ('discount use', 296),\n",
       " ('discover', 249),\n",
       " ('discuss', 137),\n",
       " ('discussion', 104),\n",
       " ('disease', 259),\n",
       " ('disgusting', 242),\n",
       " ('dish', 987),\n",
       " ('disorder', 110),\n",
       " ('ditch', 133),\n",
       " ('ditchdairy', 130),\n",
       " ('diy', 119),\n",
       " ('dm', 187),\n",
       " ('do know', 370),\n",
       " ('do not', 1275),\n",
       " ('doctor', 220),\n",
       " ('documentary', 255),\n",
       " ('dog', 1655),\n",
       " ('dog cat', 108),\n",
       " ('dollar', 104),\n",
       " ('donate', 144),\n",
       " ('dont', 144),\n",
       " ('donut', 543),\n",
       " ('door', 158),\n",
       " ('double', 250),\n",
       " ('dough', 223),\n",
       " ('doughnut', 236),\n",
       " ('dr', 323),\n",
       " ('dream', 376),\n",
       " ('dress', 207),\n",
       " ('dressing', 162),\n",
       " ('drink', 1242),\n",
       " ('drive', 293),\n",
       " ('drop', 382),\n",
       " ('drunk', 119),\n",
       " ('dry', 235),\n",
       " ('dude', 287),\n",
       " ('dumb', 276),\n",
       " ('earlier', 104),\n",
       " ('early', 188),\n",
       " ('earth', 405),\n",
       " ('easily', 156),\n",
       " ('east', 168),\n",
       " ('easter', 458),\n",
       " ('easy', 2662),\n",
       " ('eat', 13447),\n",
       " ('eat animal', 365),\n",
       " ('eat chicken', 164),\n",
       " ('eat day', 158),\n",
       " ('eat food', 365),\n",
       " ('eat good', 106),\n",
       " ('eat healthy', 217),\n",
       " ('eat in', 158),\n",
       " ('eat meat', 1579),\n",
       " ('eat not', 127),\n",
       " ('eat plant', 195),\n",
       " ('eatclean', 256),\n",
       " ('eater', 478),\n",
       " ('eating', 252),\n",
       " ('eats', 155),\n",
       " ('eco', 218),\n",
       " ('ecofriendly', 195),\n",
       " ('edge', 105),\n",
       " ('edible', 108),\n",
       " ('educate', 188),\n",
       " ('effect', 154),\n",
       " ('effort', 126),\n",
       " ('egg', 1532),\n",
       " ('eggplant', 145),\n",
       " ('eggs', 111),\n",
       " ('email', 148),\n",
       " ('encourage', 192),\n",
       " ('end', 841),\n",
       " ('energy', 572),\n",
       " ('enjoy', 1155),\n",
       " ('enter', 318),\n",
       " ('entire', 317),\n",
       " ('entrepreneur', 368),\n",
       " ('entrepreneur blogger', 165),\n",
       " ('environment', 513),\n",
       " ('environmental', 144),\n",
       " ('epic', 110),\n",
       " ('episode', 181),\n",
       " ('especially', 414),\n",
       " ('essential', 258),\n",
       " ('ethical', 470),\n",
       " ('etsy', 221),\n",
       " ('evening', 221),\n",
       " ('event', 488),\n",
       " ('everybody', 214),\n",
       " ('everyday', 287),\n",
       " ('evil', 114),\n",
       " ('exactly', 340),\n",
       " ('example', 176),\n",
       " ('excellent', 163),\n",
       " ('excited', 586),\n",
       " ('exciting', 164),\n",
       " ('excuse', 332),\n",
       " ('exercise', 440),\n",
       " ('exercise entrepreneur', 164),\n",
       " ('exercise workout', 112),\n",
       " ('exist', 488),\n",
       " ('expect', 220),\n",
       " ('expensive', 491),\n",
       " ('experience', 357),\n",
       " ('expert', 127),\n",
       " ('explain', 253),\n",
       " ('exploit', 130),\n",
       " ('exploitation', 124),\n",
       " ('explore', 117),\n",
       " ('extra', 303),\n",
       " ('extreme', 150),\n",
       " ('extremely', 154),\n",
       " ('eye', 474),\n",
       " ('fab', 147),\n",
       " ('fabulous', 150),\n",
       " ('face', 602),\n",
       " ('facebook', 331),\n",
       " ('fact', 763),\n",
       " ('factory', 178),\n",
       " ('fail', 171),\n",
       " ('fair', 301),\n",
       " ('fake', 451),\n",
       " ('falafel', 201),\n",
       " ('fall', 265),\n",
       " ('fam', 117),\n",
       " ('family', 898),\n",
       " ('famous', 121),\n",
       " ('fan', 366),\n",
       " ('fancy', 209),\n",
       " ('fantastic', 312),\n",
       " ('far', 513),\n",
       " ('farm', 637),\n",
       " ('farmer', 427),\n",
       " ('farming', 256),\n",
       " ('fashion', 437),\n",
       " ('fast', 504),\n",
       " ('fast food', 163),\n",
       " ('fat', 786),\n",
       " ('faux', 116),\n",
       " ('fav', 190),\n",
       " ('fave', 178),\n",
       " ('favorite', 1021),\n",
       " ('favourite', 461),\n",
       " ('fb', 131),\n",
       " ('fear', 127),\n",
       " ('feast', 150),\n",
       " ('feat', 119),\n",
       " ('feature', 431),\n",
       " ('february', 212),\n",
       " ('februdairy', 931),\n",
       " ('februdairy govegan', 142),\n",
       " ('feed', 1376),\n",
       " ('feed cat', 103),\n",
       " ('feel', 2556),\n",
       " ('feel good', 221),\n",
       " ('feeling', 177),\n",
       " ('fellow', 126),\n",
       " ('female', 135),\n",
       " ('feminist', 175),\n",
       " ('fennec', 131),\n",
       " ('fennec fox', 116),\n",
       " ('festival', 549),\n",
       " ('fiber', 112),\n",
       " ('fight', 347),\n",
       " ('figure', 181),\n",
       " ('film', 182),\n",
       " ('finally', 511),\n",
       " ('fine', 374),\n",
       " ('finger', 117),\n",
       " ('finish', 206),\n",
       " ('fish', 726),\n",
       " ('fit', 584),\n",
       " ('fit workout', 170),\n",
       " ('fitfood', 149),\n",
       " ('fitfood fitness', 106),\n",
       " ('fitness', 1191),\n",
       " ('fitness exercise', 112),\n",
       " ('fitness fit', 179),\n",
       " ('fix', 135),\n",
       " ('flat', 120),\n",
       " ('flavor', 621),\n",
       " ('flavour', 350),\n",
       " ('flesh', 180),\n",
       " ('fleshlustandprofit', 125),\n",
       " ('fleshlustandprofit februdairy', 119),\n",
       " ('flexible', 251),\n",
       " ('flexible motivation', 163),\n",
       " ('flour', 171),\n",
       " ('flower', 161),\n",
       " ('fluffy', 118),\n",
       " ('fly', 117),\n",
       " ('focus', 182),\n",
       " ('folk', 304),\n",
       " ('follow', 1454),\n",
       " ('follower', 174),\n",
       " ('food', 11505),\n",
       " ('food and', 118),\n",
       " ('food cook', 278),\n",
       " ('food eat', 179),\n",
       " ('food foodie', 394),\n",
       " ('food not', 174),\n",
       " ('foodblog', 331),\n",
       " ('foodblog foodporn', 293),\n",
       " ('foodblogger', 126),\n",
       " ('foodchannel', 292),\n",
       " ('foodchannel foodblog', 291),\n",
       " ('foodie', 1355),\n",
       " ('foodie hungry', 293),\n",
       " ('foodporn', 734),\n",
       " ('foodporn must', 291),\n",
       " ('foods', 382),\n",
       " ('foot', 133),\n",
       " ('for the', 106),\n",
       " ('force', 936),\n",
       " ('force diet', 117),\n",
       " ('forever', 188),\n",
       " ('forget', 469),\n",
       " ('form', 217),\n",
       " ('forward', 229),\n",
       " ('foundation', 124),\n",
       " ('fox', 699),\n",
       " ('freak', 117),\n",
       " ('free', 5188),\n",
       " ('freebiefriday', 113),\n",
       " ('freeze', 129),\n",
       " ('french', 326),\n",
       " ('fresh', 952),\n",
       " ('friday', 425),\n",
       " ('fridayfeeling', 120),\n",
       " ('fridge', 131),\n",
       " ('fried', 134),\n",
       " ('friend', 2080),\n",
       " ('friendly', 973),\n",
       " ('frozen', 244),\n",
       " ('fruit', 1083),\n",
       " ('fry', 974),\n",
       " ('fuck', 2042),\n",
       " ('fuckin', 193),\n",
       " ('fucking', 868),\n",
       " ('fudge', 172),\n",
       " ('fuel', 140),\n",
       " ('full info', 292),\n",
       " ('fully', 362),\n",
       " ('fun', 634),\n",
       " ('funny', 378),\n",
       " ('fur', 379),\n",
       " ('future', 387),\n",
       " ('gain', 266),\n",
       " ('game', 375),\n",
       " ('garden', 275),\n",
       " ('garlic', 562),\n",
       " ('gas', 272),\n",
       " ('gas make', 141),\n",
       " ('gay', 211),\n",
       " ('general', 103),\n",
       " ('get discount', 403),\n",
       " ('get recipe', 134),\n",
       " ('get to', 461),\n",
       " ('gf', 375),\n",
       " ('gift', 730),\n",
       " ('ginger', 277),\n",
       " ('girl', 1423),\n",
       " ('giveaway', 413),\n",
       " ('glad', 355),\n",
       " ('glass', 151),\n",
       " ('global', 154),\n",
       " ('glow', 140),\n",
       " ('gluten', 1762),\n",
       " ('gluten free', 1507),\n",
       " ('glutenfree', 3640),\n",
       " ('glutenfree dairyfree', 230),\n",
       " ('gmo', 135),\n",
       " ('go be', 113),\n",
       " ('go coachella', 140),\n",
       " ('go day', 146),\n",
       " ('go eat', 146),\n",
       " ('go month', 102),\n",
       " ('go not', 114),\n",
       " ('go to', 1228),\n",
       " ('go try', 116),\n",
       " ('go vegetarian', 118),\n",
       " ('goal', 230),\n",
       " ('god', 685),\n",
       " ('gold', 143),\n",
       " ('golden', 111),\n",
       " ('good', 9376),\n",
       " ('good day', 104),\n",
       " ('good food', 230),\n",
       " ('good friend', 125),\n",
       " ('good luck', 198),\n",
       " ('good morning', 150),\n",
       " ('good place', 101),\n",
       " ('good thing', 253),\n",
       " ('good way', 138),\n",
       " ('goodness', 206),\n",
       " ('goody', 147),\n",
       " ('google', 216),\n",
       " ('gorgeous', 220),\n",
       " ('got', 163),\n",
       " ('gourmet', 118),\n",
       " ('govegan', 2014),\n",
       " ('govegan meatymarch', 119),\n",
       " ('government', 127),\n",
       " ('grab', 256),\n",
       " ('grain', 239),\n",
       " ('granola', 177),\n",
       " ('grass', 266),\n",
       " ('gravy', 140),\n",
       " ('great', 2924),\n",
       " ('green', 1587),\n",
       " ('green planet', 201),\n",
       " ('green tea', 111),\n",
       " ('greenbeauty', 109),\n",
       " ('greens', 383),\n",
       " ('greens smoothies', 276),\n",
       " ('grill', 343),\n",
       " ('grill cheese', 111),\n",
       " ('groceries', 386),\n",
       " ('grocery', 416),\n",
       " ('grocery store', 120),\n",
       " ('gross', 238),\n",
       " ('ground', 173),\n",
       " ('group', 399),\n",
       " ('grow', 707),\n",
       " ('growth', 107),\n",
       " ('gt', 377),\n",
       " ('gtgt', 276),\n",
       " ('guacamole', 121),\n",
       " ('guess', 723),\n",
       " ('guest', 158),\n",
       " ('guide', 462),\n",
       " ('gun', 140),\n",
       " ('guy', 1091),\n",
       " ('gym', 287),\n",
       " ('ha', 139),\n",
       " ('habit', 149),\n",
       " ('haha', 274),\n",
       " ('hair', 525),\n",
       " ('halal', 118),\n",
       " ('half', 407),\n",
       " ('hall', 121),\n",
       " ('ham', 172),\n",
       " ('hand', 539),\n",
       " ('handbag', 154),\n",
       " ('handle', 111),\n",
       " ('handmade', 426),\n",
       " ('hang', 134),\n",
       " ('happen', 777),\n",
       " ('happiness', 146),\n",
       " ('happy', 2047),\n",
       " ('happy birthday', 119),\n",
       " ('happy cooking', 293),\n",
       " ('hard', 1162),\n",
       " ('harm', 227),\n",
       " ('hat', 400),\n",
       " ('hate', 801),\n",
       " ('haul', 169),\n",
       " ('have eat', 166),\n",
       " ('have get', 448),\n",
       " ('have go', 127),\n",
       " ('have hear', 136),\n",
       " ('have see', 259),\n",
       " ('have try', 437),\n",
       " ('have year', 158),\n",
       " ('hazelnut', 140),\n",
       " ('head', 791),\n",
       " ('heal', 137),\n",
       " ('health', 3951),\n",
       " ('health benefit', 180),\n",
       " ('health fitness', 192),\n",
       " ('health healthtip', 108),\n",
       " ('health healthy', 277),\n",
       " ('health nutrition', 114),\n",
       " ('health skincare', 286),\n",
       " ('healthadvice', 106),\n",
       " ('healthadvice healthy', 105),\n",
       " ('healthtip', 127),\n",
       " ('healthtip healthadvice', 106),\n",
       " ('healthy', 5142),\n",
       " ('healthy blog', 166),\n",
       " ('healthy food', 157),\n",
       " ('healthy lifestyle', 100),\n",
       " ('healthy nutrition', 131),\n",
       " ('healthy organic', 101),\n",
       " ('healthyeat', 311),\n",
       " ('healthyeating', 182),\n",
       " ('healthyfood', 1922),\n",
       " ('healthyfood recipe', 1344),\n",
       " ('healthylifestyle', 326),\n",
       " ('healthyliv', 146),\n",
       " ('healthyliving', 195),\n",
       " ('healthyrecipe', 107),\n",
       " ('hear', 1011),\n",
       " ('heart', 853),\n",
       " ('heart attack', 128),\n",
       " ('hearty', 226),\n",
       " ('heat', 123),\n",
       " ('heaven', 168),\n",
       " ('heavy', 102),\n",
       " ('hell', 488),\n",
       " ('hella', 131),\n",
       " ('hello', 285),\n",
       " ('help', 2278),\n",
       " ('helpful', 101),\n",
       " ('hemp', 340),\n",
       " ('herb', 177),\n",
       " ('herbivore', 147),\n",
       " ('here ’', 172),\n",
       " ('heres', 330),\n",
       " ('hey', 781),\n",
       " ('hi', 518),\n",
       " ('hide', 111),\n",
       " ('high', 949),\n",
       " ('high protein', 142),\n",
       " ('highly', 161),\n",
       " ('hippie', 138),\n",
       " ('hipster', 104),\n",
       " ('history', 135),\n",
       " ('hit', 390),\n",
       " ('hoe', 122),\n",
       " ('hold', 274),\n",
       " ('holiday', 129),\n",
       " ('hollywood', 124),\n",
       " ('holy', 178),\n",
       " ('home', 1056),\n",
       " ('homemade', 1043),\n",
       " ('honest', 106),\n",
       " ('honestly', 581),\n",
       " ('honey', 441),\n",
       " ('hop', 170),\n",
       " ('hope', 875),\n",
       " ('hopefully', 149),\n",
       " ('horrible', 135),\n",
       " ('host', 226),\n",
       " ('hot', 1180),\n",
       " ('hot chocolate', 150),\n",
       " ('hot dog', 151),\n",
       " ('hotel', 129),\n",
       " ('hour', 495),\n",
       " ('house', 610),\n",
       " ('how make', 124),\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_word_freq = sorted(freq, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eat', 13447),\n",
       " ('food', 11505),\n",
       " ('good', 9376),\n",
       " ('recipe', 9134),\n",
       " ('’', 8921),\n",
       " ('animal', 8128),\n",
       " ('vegetarian', 7251),\n",
       " ('meat', 6863),\n",
       " ('diet', 6853),\n",
       " ('try', 6414),\n",
       " ('love', 6368),\n",
       " ('people', 6090),\n",
       " ('day', 5850),\n",
       " ('know', 5568),\n",
       " ('free', 5188),\n",
       " ('healthy', 5142),\n",
       " ('new', 5128),\n",
       " ('time', 4506),\n",
       " ('make', 4402),\n",
       " ('need', 4395),\n",
       " ('look', 4232),\n",
       " ('cheese', 4171),\n",
       " ('health', 3951),\n",
       " ('glutenfree', 3640),\n",
       " ('say', 3560),\n",
       " ('today', 3499),\n",
       " ('thank', 3443),\n",
       " ('delicious', 3437),\n",
       " ('thing', 3404),\n",
       " ('come', 3375),\n",
       " ('organic', 3372),\n",
       " ('life', 3291),\n",
       " ('chocolate', 3244),\n",
       " ('milk', 3085),\n",
       " ('great', 2924),\n",
       " ('’s', 2888),\n",
       " ('year', 2862),\n",
       " ('video', 2812),\n",
       " ('product', 2712),\n",
       " ('way', 2668),\n",
       " ('easy', 2662),\n",
       " ('meal', 2568),\n",
       " ('feel', 2556),\n",
       " ('live', 2552),\n",
       " ('tell', 2547),\n",
       " ('veganism', 2517),\n",
       " ('rt', 2472),\n",
       " ('dairy', 2448),\n",
       " ('raw', 2433),\n",
       " ('start', 2400),\n",
       " ('veggie', 2398),\n",
       " ('week', 2398),\n",
       " ('option', 2374),\n",
       " ('chicken', 2364),\n",
       " ('plant', 2359),\n",
       " ('beyoncé', 2327),\n",
       " ('use', 2288),\n",
       " ('help', 2278),\n",
       " ('lol', 2263),\n",
       " ('protein', 2251),\n",
       " ('plantbas', 2205),\n",
       " ('burger', 2183),\n",
       " ('right', 2173),\n",
       " ('pizza', 2165),\n",
       " ('check', 2106),\n",
       " ('work', 2102),\n",
       " ('just', 2089),\n",
       " ('friend', 2080),\n",
       " ('cake', 2074),\n",
       " ('cook', 2073),\n",
       " ('happy', 2047),\n",
       " ('fuck', 2042),\n",
       " ('plantbased', 2019),\n",
       " ('govegan', 2014),\n",
       " ('yes', 1978),\n",
       " ('shit', 1963),\n",
       " ('crueltyfree', 1957),\n",
       " ('stop', 1940),\n",
       " ('cream', 1938),\n",
       " ('healthyfood', 1922),\n",
       " ('restaurant', 1919),\n",
       " ('taste', 1893),\n",
       " ('buy', 1872),\n",
       " ('add', 1834),\n",
       " ('please rt', 1816),\n",
       " ('breakfast', 1814),\n",
       " ('amazing', 1762),\n",
       " ('gluten', 1762),\n",
       " ('mean', 1758),\n",
       " ('lot', 1752),\n",
       " ('watch', 1751),\n",
       " ('post', 1725),\n",
       " ('dinner', 1716),\n",
       " ('soup', 1715),\n",
       " ('month', 1694),\n",
       " ('let', 1687),\n",
       " ('sweet', 1668),\n",
       " ('dog', 1655),\n",
       " ('lunch', 1652),\n",
       " ('salad', 1650),\n",
       " ('lifestyle', 1626),\n",
       " ('green', 1587),\n",
       " ('eat meat', 1579),\n",
       " ('actually', 1558),\n",
       " ('bad', 1555),\n",
       " ('world', 1552),\n",
       " ('natural', 1541),\n",
       " ('egg', 1532),\n",
       " ('base', 1513),\n",
       " ('gluten free', 1507),\n",
       " ('cooking', 1484),\n",
       " ('ask', 1462),\n",
       " ('late', 1457),\n",
       " ('dairyfree', 1455),\n",
       " ('follow', 1454),\n",
       " ('place', 1449),\n",
       " ('girl', 1423),\n",
       " ('save', 1413),\n",
       " ('cruelty', 1410),\n",
       " ('potato', 1406),\n",
       " ('change', 1384),\n",
       " ('butter', 1376),\n",
       " ('feed', 1376),\n",
       " ('vegetarian healthyfood', 1361),\n",
       " ('foodie', 1355),\n",
       " ('talk', 1355),\n",
       " ('healthyfood recipe', 1344),\n",
       " ('rt vegetarian', 1335),\n",
       " ('body', 1334),\n",
       " ('menu', 1313),\n",
       " ('bean', 1306),\n",
       " ('reason', 1301),\n",
       " ('beauty', 1289),\n",
       " ('shop', 1289),\n",
       " ('do not', 1275),\n",
       " ('sure', 1272),\n",
       " ('coconut', 1271),\n",
       " ('veganfood', 1269),\n",
       " ('beyonce', 1258),\n",
       " ('bitch', 1257),\n",
       " ('perfect', 1251),\n",
       " ('cookie', 1249),\n",
       " ('sauce', 1246),\n",
       " ('care', 1243),\n",
       " ('drink', 1242),\n",
       " ('go to', 1228),\n",
       " ('read', 1214),\n",
       " ('order', 1210),\n",
       " ('tofu', 1202),\n",
       " ('nutrition', 1201),\n",
       " ('rice', 1200),\n",
       " ('ice', 1199),\n",
       " ('cat', 1196),\n",
       " ('fitness', 1191),\n",
       " ('little', 1185),\n",
       " ('hot', 1180),\n",
       " ('real', 1176),\n",
       " ('black', 1175),\n",
       " ('vegetable', 1172),\n",
       " ('oh', 1171),\n",
       " ('big', 1170),\n",
       " ('blog', 1170),\n",
       " ('pet', 1165),\n",
       " ('recipes', 1164),\n",
       " ('hard', 1162),\n",
       " ('enjoy', 1155),\n",
       " ('night', 1154),\n",
       " ('share', 1152),\n",
       " ('available', 1150),\n",
       " ('treat', 1142),\n",
       " ('man', 1116),\n",
       " ('wait', 1116),\n",
       " ('wanna', 1113),\n",
       " ('like video', 1109),\n",
       " ('kill', 1104),\n",
       " ('human', 1099),\n",
       " ('guy', 1091),\n",
       " ('makeup', 1089),\n",
       " ('fruit', 1083),\n",
       " ('tonight', 1076),\n",
       " ('be go', 1072),\n",
       " ('skincare', 1070),\n",
       " ('oil', 1069),\n",
       " ('white', 1066),\n",
       " ('win', 1064),\n",
       " ('cow', 1062),\n",
       " ('home', 1056),\n",
       " ('yoga', 1053),\n",
       " ('not eat', 1049),\n",
       " ('march', 1046),\n",
       " ('homemade', 1043),\n",
       " ('ice cream', 1042),\n",
       " ('stuff', 1027),\n",
       " ('ingredient', 1024),\n",
       " ('favorite', 1021),\n",
       " ('skin', 1021),\n",
       " ('snack', 1020),\n",
       " ('long', 1015),\n",
       " ('news', 1012),\n",
       " ('hear', 1011),\n",
       " ('turn', 1009),\n",
       " ('tasty', 1007),\n",
       " ('be not', 1001),\n",
       " ('daily', 999),\n",
       " ('support', 999),\n",
       " ('super', 996),\n",
       " ('open', 993),\n",
       " ('bacon', 991),\n",
       " ('dish', 987),\n",
       " ('fry', 974),\n",
       " ('friendly', 973),\n",
       " ('red', 970),\n",
       " ('bread', 969),\n",
       " ('choice', 960),\n",
       " ('chef', 957),\n",
       " ('literally', 957),\n",
       " ('tweet', 957),\n",
       " ('ass', 955),\n",
       " ('fresh', 952),\n",
       " ('high', 949),\n",
       " ('lmao', 947),\n",
       " ('bar', 946),\n",
       " ('yummy', 940),\n",
       " ('pie', 937),\n",
       " ('smoothie', 937),\n",
       " ('coffee', 936),\n",
       " ('force', 936),\n",
       " ('morning', 936),\n",
       " ('februdairy', 931),\n",
       " ('bc', 926),\n",
       " ('plant base', 922),\n",
       " ('the late', 915),\n",
       " ('person', 912),\n",
       " ('miss', 911),\n",
       " ('water', 911),\n",
       " ('die', 910),\n",
       " ('banana', 908),\n",
       " ('family', 898),\n",
       " ('baby', 896),\n",
       " ('almond', 894),\n",
       " ('coachella', 891),\n",
       " ('not know', 889),\n",
       " ('hope', 875),\n",
       " ('link', 875),\n",
       " ('bake', 871),\n",
       " ('bring', 871),\n",
       " ('ur', 870),\n",
       " ('fucking', 868),\n",
       " ('meatymarch', 865),\n",
       " ('mushroom', 860),\n",
       " ('book', 858),\n",
       " ('bowl', 858),\n",
       " ('uk', 857),\n",
       " ('brand', 855),\n",
       " ('heart', 853),\n",
       " ('believe', 847),\n",
       " ('leather', 847),\n",
       " ('code', 846),\n",
       " ('end', 841),\n",
       " ('pretty', 841),\n",
       " ('join', 839),\n",
       " ('choose', 838),\n",
       " ('curry', 838),\n",
       " ('serve', 838),\n",
       " ('cruelty free', 835),\n",
       " ('avocado', 822),\n",
       " ('offer', 822),\n",
       " ('weight', 817),\n",
       " ('paleo', 816),\n",
       " ('maybe', 812),\n",
       " ('idea', 810),\n",
       " ('soy', 804),\n",
       " ('chip', 802),\n",
       " ('hate', 801),\n",
       " ('leave', 801),\n",
       " ('pasta', 795),\n",
       " ('head', 791),\n",
       " ('fat', 786),\n",
       " ('planet', 785),\n",
       " ('include', 783),\n",
       " ('tomato', 783),\n",
       " ('tomorrow', 783),\n",
       " ('sell', 782),\n",
       " ('hey', 781),\n",
       " ('lose', 781),\n",
       " ('ok', 778),\n",
       " ('happen', 777),\n",
       " ('store', 775),\n",
       " ('twitter', 772),\n",
       " ('yeah', 772),\n",
       " ('nice', 770),\n",
       " ('sandwich', 766),\n",
       " ('woman', 766),\n",
       " ('fact', 763),\n",
       " ('taco', 763),\n",
       " ('travel', 763),\n",
       " ('point', 757),\n",
       " ('mac', 753),\n",
       " ('sunday', 751),\n",
       " ('weekend', 743),\n",
       " ('ready', 741),\n",
       " ('foodporn', 734),\n",
       " ('peanut', 734),\n",
       " ('plan', 731),\n",
       " ('gift', 730),\n",
       " ('fish', 726),\n",
       " ('alternative', 724),\n",
       " ('beautiful', 724),\n",
       " ('learn', 724),\n",
       " ('guess', 723),\n",
       " ('will not', 722),\n",
       " ('hungry', 721),\n",
       " ('weightloss', 721),\n",
       " ('dessert', 715),\n",
       " ('sugar', 715),\n",
       " ('kind', 712),\n",
       " ('wrong', 710),\n",
       " ('soon', 709),\n",
       " ('tea', 708),\n",
       " ('grow', 707),\n",
       " ('vegans', 704),\n",
       " ('beef', 702),\n",
       " ('fox', 699),\n",
       " ('awesome', 697),\n",
       " ('stay', 697),\n",
       " ('away', 696),\n",
       " ('damn', 696),\n",
       " ('sorry', 694),\n",
       " ('ill', 692),\n",
       " ('industry', 692),\n",
       " ('low', 690),\n",
       " ('discount', 686),\n",
       " ('god', 685),\n",
       " ('cafe', 684),\n",
       " ('probably', 684),\n",
       " ('simple', 684),\n",
       " ('word', 679),\n",
       " ('review', 677),\n",
       " ('wish', 674),\n",
       " ('bag', 669),\n",
       " ('consider', 667),\n",
       " ('carrot', 665),\n",
       " ('meet', 660),\n",
       " ('challenge', 659),\n",
       " ('different', 652),\n",
       " ('creamy', 651),\n",
       " ('steak', 649),\n",
       " ('sound', 648),\n",
       " ('veg', 643),\n",
       " ('farm', 637),\n",
       " ('list', 637),\n",
       " ('market', 636),\n",
       " ('true', 635),\n",
       " ('fun', 634),\n",
       " ('mind', 633),\n",
       " ('non', 630),\n",
       " ('understand', 628),\n",
       " ('veganlife', 628),\n",
       " ('wow', 627),\n",
       " ('cauliflower', 626),\n",
       " ('break', 623),\n",
       " ('kid', 623),\n",
       " ('run', 623),\n",
       " ('wine', 623),\n",
       " ('flavor', 621),\n",
       " ('house', 610),\n",
       " ('benefit', 605),\n",
       " ('old', 605),\n",
       " ('sale', 604),\n",
       " ('face', 602),\n",
       " ('workout', 602),\n",
       " ('question', 601),\n",
       " ('yum', 599),\n",
       " ('kitchen', 597),\n",
       " ('sausage', 597),\n",
       " ('snow', 597),\n",
       " ('spicy', 597),\n",
       " ('chickpea', 596),\n",
       " ('sweet potato', 593),\n",
       " ('tho', 593),\n",
       " ('bit', 592),\n",
       " ('cut', 589),\n",
       " ('instead', 589),\n",
       " ('visit', 589),\n",
       " ('lentil', 588),\n",
       " ('excited', 586),\n",
       " ('fit', 584),\n",
       " ('mad', 584),\n",
       " ('omg', 584),\n",
       " ('warm', 584),\n",
       " ('definitely', 583),\n",
       " ('honestly', 581),\n",
       " ('local', 580),\n",
       " ('peanut butter', 578),\n",
       " ('cool', 577),\n",
       " ('wrap', 576),\n",
       " ('blogger', 574),\n",
       " ('london', 574),\n",
       " ('cold', 572),\n",
       " ('energy', 572),\n",
       " ('abuse', 567),\n",
       " ('garlic', 562),\n",
       " ('wear', 562),\n",
       " ('muscle', 561),\n",
       " ('special', 561),\n",
       " ('animal product', 558),\n",
       " ('better', 558),\n",
       " ('business', 556),\n",
       " ('info', 554),\n",
       " ('skinny', 551),\n",
       " ('create', 550),\n",
       " ('festival', 549),\n",
       " ('bbq', 547),\n",
       " ('nongmo', 547),\n",
       " ('veganhour', 547),\n",
       " ('wonder', 547),\n",
       " ('quick', 546),\n",
       " ('roll', 546),\n",
       " ('nut', 545),\n",
       " ('pig', 544),\n",
       " ('donut', 543),\n",
       " ('kale', 543),\n",
       " ('date', 542),\n",
       " ('cookbook', 539),\n",
       " ('hand', 539),\n",
       " ('mac cheese', 539),\n",
       " ('mom', 538),\n",
       " ('playlist', 538),\n",
       " ('onion', 537),\n",
       " ('pack', 537),\n",
       " ('send', 537),\n",
       " ('course', 534),\n",
       " ('lovely', 534),\n",
       " ('veganrecipe', 531),\n",
       " ('spot', 529),\n",
       " ('whatveganseat', 528),\n",
       " ('cheap', 526),\n",
       " ('birthday', 525),\n",
       " ('hair', 525),\n",
       " ('add video', 521),\n",
       " ('tip', 521),\n",
       " ('video playlist', 521),\n",
       " ('hi', 518),\n",
       " ('environment', 513),\n",
       " ('far', 513),\n",
       " ('style', 512),\n",
       " ('chili', 511),\n",
       " ('finally', 511),\n",
       " ('spinach', 511),\n",
       " ('pepper', 510),\n",
       " ('range', 510),\n",
       " ('company', 505),\n",
       " ('fast', 504),\n",
       " ('ppl', 503),\n",
       " ('ya', 503),\n",
       " ('decide', 500),\n",
       " ('lemon', 499),\n",
       " ('line', 499),\n",
       " ('spring', 497),\n",
       " ('roasted', 496),\n",
       " ('cancer', 495),\n",
       " ('hour', 495),\n",
       " ('plus', 495),\n",
       " ('seed', 494),\n",
       " ('pick', 492),\n",
       " ('powder', 492),\n",
       " ('expensive', 491),\n",
       " ('instagram', 491),\n",
       " ('listen', 491),\n",
       " ('minute', 490),\n",
       " ('remember', 490),\n",
       " ('apple', 489),\n",
       " ('event', 488),\n",
       " ('exist', 488),\n",
       " ('hell', 488),\n",
       " ('test', 488),\n",
       " ('vitamins', 488),\n",
       " ('ago', 487),\n",
       " ('supplements', 487),\n",
       " ('best', 486),\n",
       " ('soap', 485),\n",
       " ('step', 485),\n",
       " ('brownie', 484),\n",
       " ('community', 483),\n",
       " ('agree', 482),\n",
       " ('carnivore', 482),\n",
       " ('poor', 481),\n",
       " ('story', 480),\n",
       " ('eater', 478),\n",
       " ('not wait', 478),\n",
       " ('type', 477),\n",
       " ('source', 476),\n",
       " ('pancake', 475),\n",
       " ('eye', 474),\n",
       " ('issue', 474),\n",
       " ('box', 473),\n",
       " ('noodle', 473),\n",
       " ('money', 472),\n",
       " ('juice', 471),\n",
       " ('online', 471),\n",
       " ('ethical', 470),\n",
       " ('forget', 469),\n",
       " ('queen', 469),\n",
       " ('imagine', 468),\n",
       " ('celebrate', 465),\n",
       " ('slaughter', 465),\n",
       " ('quinoa', 464),\n",
       " ('bey', 463),\n",
       " ('guide', 462),\n",
       " ('favourite', 461),\n",
       " ('get to', 461),\n",
       " ('bodybuilding', 459),\n",
       " ('late the', 459),\n",
       " ('meatlessmarch', 459),\n",
       " ('speak', 459),\n",
       " ('easter', 458),\n",
       " ('set', 458),\n",
       " ('version', 457),\n",
       " ('problem', 456),\n",
       " ('art', 455),\n",
       " ('clean', 454),\n",
       " ('cuisine', 453),\n",
       " ('cute', 451),\n",
       " ('fake', 451),\n",
       " ('veganfoodshare', 451),\n",
       " ('have get', 448),\n",
       " ('light', 445),\n",
       " ('motivation', 442),\n",
       " ('honey', 441),\n",
       " ('music', 441),\n",
       " ('exercise', 440),\n",
       " ('mother', 440),\n",
       " ('nonvegan', 439),\n",
       " ('pay', 439),\n",
       " ('fashion', 437),\n",
       " ('have try', 437),\n",
       " ('child', 434),\n",
       " ('saturday', 434),\n",
       " ('shake', 434),\n",
       " ('cinnamon', 431),\n",
       " ('feature', 431),\n",
       " ('street', 431),\n",
       " ('completely', 430),\n",
       " ('compassion', 429),\n",
       " ('roast', 429),\n",
       " ('youtube', 429),\n",
       " ('couple', 428),\n",
       " ('farmer', 427),\n",
       " ('handmade', 426),\n",
       " ('recommend', 426),\n",
       " ('research', 426),\n",
       " ('friday', 425),\n",
       " ('wild', 424),\n",
       " ('absolutely', 423),\n",
       " ('shut', 420),\n",
       " ('case', 419),\n",
       " ('stick', 419),\n",
       " ('claim', 418),\n",
       " ('difference', 418),\n",
       " ('cashew', 417),\n",
       " ('veganvegetarian', 417),\n",
       " ('grocery', 416),\n",
       " ('proud', 416),\n",
       " ('yesterday', 415),\n",
       " ('especially', 414),\n",
       " ('giveaway', 413),\n",
       " ('animalrights', 410),\n",
       " ('retweet', 410),\n",
       " ('class', 409),\n",
       " ('monday', 409),\n",
       " ('sick', 409),\n",
       " ('small', 409),\n",
       " ('that ’', 408),\n",
       " ('half', 407),\n",
       " ('idk', 407),\n",
       " ('process', 407),\n",
       " ('able', 406),\n",
       " ('blueberry', 406),\n",
       " ('earth', 405),\n",
       " ('launch', 405),\n",
       " ('produce', 405),\n",
       " ('sign', 405),\n",
       " ('spread', 405),\n",
       " ('chance', 404),\n",
       " ('play', 404),\n",
       " ('get discount', 403),\n",
       " ('beer', 402),\n",
       " ('picture', 402),\n",
       " ('daily thank', 401),\n",
       " ('hat', 400),\n",
       " ('group', 399),\n",
       " ('cheesecake', 398),\n",
       " ('la', 398),\n",
       " ('vitamin', 398),\n",
       " ('can not', 397),\n",
       " ('power', 397),\n",
       " ('death', 396),\n",
       " ('strawberry', 396),\n",
       " ('brunch', 395),\n",
       " ('crazy', 395),\n",
       " ('toast', 395),\n",
       " ('food foodie', 394),\n",
       " ('party', 393),\n",
       " ('what eat', 393),\n",
       " ('air', 391),\n",
       " ('sad', 391),\n",
       " ('stupid', 391),\n",
       " ('broccoli', 390),\n",
       " ('hit', 390),\n",
       " ('almond milk', 389),\n",
       " ('cookies', 389),\n",
       " ('inspire', 389),\n",
       " ('bio', 388),\n",
       " ('recip', 388),\n",
       " ('respect', 388),\n",
       " ('veganuary', 388),\n",
       " ('future', 387),\n",
       " ('groceries', 386),\n",
       " ('keto', 386),\n",
       " ('spend', 386),\n",
       " ('huge', 385),\n",
       " ('realize', 385),\n",
       " ('totally', 385),\n",
       " ('bomb', 384),\n",
       " ('mix', 384),\n",
       " ('greens', 383),\n",
       " ('comment', 382),\n",
       " ('drop', 382),\n",
       " ('foods', 382),\n",
       " ('supplement', 382),\n",
       " ('article', 381),\n",
       " ('superfood', 381),\n",
       " ('veganlifestyle', 381),\n",
       " ('vitamins supplements', 380),\n",
       " ('fur', 379),\n",
       " ('funny', 378),\n",
       " ('gt', 377),\n",
       " ('deal', 376),\n",
       " ('dream', 376),\n",
       " ('game', 375),\n",
       " ('gf', 375),\n",
       " ('seriously', 375),\n",
       " ('fine', 374),\n",
       " ('peta', 374),\n",
       " ('nature', 372),\n",
       " ('city', 371),\n",
       " ('cupcake', 371),\n",
       " ('do know', 370),\n",
       " ('pork', 370),\n",
       " ('school', 370),\n",
       " ('worth', 370),\n",
       " ('entrepreneur', 368),\n",
       " ('vanilla', 368),\n",
       " ('dead', 367),\n",
       " ('people not', 367),\n",
       " ('switch', 367),\n",
       " ('close', 366),\n",
       " ('fan', 366),\n",
       " ('smoothies', 366),\n",
       " ('walk', 366),\n",
       " ('eat animal', 365),\n",
       " ('eat food', 365),\n",
       " ('salt', 365),\n",
       " ('dairy free', 364),\n",
       " ('pop', 363),\n",
       " ('fully', 362),\n",
       " ('promote', 361),\n",
       " ('supplements beauty', 361),\n",
       " ('annoying', 360),\n",
       " ('prep', 359),\n",
       " ('raise', 359),\n",
       " ('wellness', 359),\n",
       " ('pot', 358),\n",
       " ('experience', 357),\n",
       " ('skincare makeup', 357),\n",
       " ('important', 356),\n",
       " ('matter', 356),\n",
       " ('cup', 355),\n",
       " ('glad', 355),\n",
       " ('single', 355),\n",
       " ('thai', 355),\n",
       " ('consume', 354),\n",
       " ('boy', 353),\n",
       " ('sushi', 353),\n",
       " ('vegetarianvegan', 353),\n",
       " ('baked', 352),\n",
       " ('mention', 351),\n",
       " ('flavour', 350),\n",
       " ('reduce', 349),\n",
       " ('veganfriendly', 348),\n",
       " ('fight', 347),\n",
       " ('orange', 347),\n",
       " ('possible', 347),\n",
       " ('recipe food', 347),\n",
       " ('website', 347),\n",
       " ('rich', 346),\n",
       " ('weather', 346),\n",
       " ('grill', 343),\n",
       " ('plate', 343),\n",
       " ('wing', 343),\n",
       " ('winter', 343),\n",
       " ('ad', 342),\n",
       " ('meat dairy', 342),\n",
       " ('slice', 342),\n",
       " ('hummus', 341),\n",
       " ('spice', 341),\n",
       " ('throw', 341),\n",
       " ('transition', 341),\n",
       " ('exactly', 340),\n",
       " ('hemp', 340),\n",
       " ('carb', 339),\n",
       " ('near', 338),\n",
       " ('mum', 337),\n",
       " ('stock', 337),\n",
       " ('activist', 335),\n",
       " ('announce', 335),\n",
       " ('corn', 335),\n",
       " ('level', 335),\n",
       " ('photo', 335),\n",
       " ('weird', 335),\n",
       " ('sit', 334),\n",
       " ('social', 334),\n",
       " ('truth', 334),\n",
       " ('blood', 332),\n",
       " ('click', 332),\n",
       " ('contain', 332),\n",
       " ('excuse', 332),\n",
       " ('facebook', 331),\n",
       " ('foodblog', 331),\n",
       " ('meat eater', 331),\n",
       " ('yo', 331),\n",
       " ('dark', 330),\n",
       " ('heres', 330),\n",
       " ('welcome', 330),\n",
       " ('season', 329),\n",
       " ('joke', 328),\n",
       " ('mint', 327),\n",
       " ('french', 326),\n",
       " ('healthylifestyle', 326),\n",
       " ('nongmos', 326),\n",
       " ('pumpkin', 326),\n",
       " ('alive', 325),\n",
       " ('cover', 325),\n",
       " ('write', 325),\n",
       " ('label', 324),\n",
       " ('lie', 324),\n",
       " ('chocolate chip', 323),\n",
       " ('dr', 323),\n",
       " ('officially', 322),\n",
       " ('carnivorous', 321),\n",
       " ('journey', 321),\n",
       " ('answer', 320),\n",
       " ('pea', 320),\n",
       " ('second', 319),\n",
       " ('enter', 318),\n",
       " ('wtf', 318),\n",
       " ('brown', 317),\n",
       " ('entire', 317),\n",
       " ('anymore', 316),\n",
       " ('munchies', 316),\n",
       " ('cooking recipe', 315),\n",
       " ('p.m.', 315),\n",
       " ('lead', 313),\n",
       " ('piece', 313),\n",
       " ('soul', 313),\n",
       " ('substitute', 313),\n",
       " ('attack', 312),\n",
       " ('chilli', 312),\n",
       " ('dinnertime', 312),\n",
       " ('fantastic', 312),\n",
       " ('indian', 312),\n",
       " ('be eat', 311),\n",
       " ('healthyeat', 311),\n",
       " ('black bean', 310),\n",
       " ('pure', 307),\n",
       " ('cause', 306),\n",
       " ('continue', 305),\n",
       " ('stand', 305),\n",
       " ('comfort', 304),\n",
       " ('folk', 304),\n",
       " ('strong', 304),\n",
       " ('extra', 303),\n",
       " ('load', 303),\n",
       " ('smoke', 303),\n",
       " ('suffer', 303),\n",
       " ('summer', 303),\n",
       " ('aqu143', 302),\n",
       " ('code aqu143', 302),\n",
       " ('fair', 301),\n",
       " ('the good', 301),\n",
       " ('caramel', 300),\n",
       " ('rt recipe', 300),\n",
       " ('thread', 300),\n",
       " ('country', 299),\n",
       " ('not mean', 299),\n",
       " ('tbh', 299),\n",
       " ('if not', 298),\n",
       " ('burrito', 297),\n",
       " ('lady', 297),\n",
       " ('survive', 297),\n",
       " ('verified', 297),\n",
       " ('dip', 296),\n",
       " ('discount use', 296),\n",
       " ('not need', 296),\n",
       " ('smoothies nongmos', 296),\n",
       " ('blue', 295),\n",
       " ('pic', 295),\n",
       " ('simply', 295),\n",
       " ('straight', 295),\n",
       " ('beauty bodybuilding', 294),\n",
       " ('info recipe', 294),\n",
       " ('mango', 294),\n",
       " ('mayo', 294),\n",
       " ('must watch', 294),\n",
       " ('oatmeal', 294),\n",
       " ('animalright', 293),\n",
       " ('drive', 293),\n",
       " ('foodblog foodporn', 293),\n",
       " ('foodie hungry', 293),\n",
       " ('happy cooking', 293),\n",
       " ('item', 293),\n",
       " ('wonderful', 293),\n",
       " ('chef dinnertime', 292),\n",
       " ('cooking maincuisine', 292),\n",
       " ('cuisine food', 292),\n",
       " ('dinnertime foodchannel', 292),\n",
       " ('foodchannel', 292),\n",
       " ('full info', 292),\n",
       " ('hungry chef', 292),\n",
       " ('maincuisine', 292),\n",
       " ('maincuisine cooking', 292),\n",
       " ('opinion', 292),\n",
       " ('recipe cuisine', 292),\n",
       " ('foodchannel foodblog', 291),\n",
       " ('foodporn must', 291),\n",
       " ('let know', 291),\n",
       " ('prepare', 291),\n",
       " ('pudding', 290),\n",
       " ('study', 290),\n",
       " ('truly', 290),\n",
       " ('af', 289),\n",
       " ('amazon', 289),\n",
       " ('pain', 288),\n",
       " ('really', 288),\n",
       " ('smell', 288),\n",
       " ('st', 288),\n",
       " ('act', 287),\n",
       " ('dude', 287),\n",
       " ('everyday', 287),\n",
       " ('gym', 287),\n",
       " ('personal', 287),\n",
       " ('sis', 287),\n",
       " ('health skincare', 286),\n",
       " ('pls', 286),\n",
       " ('regular', 286),\n",
       " ('view', 286),\n",
       " ('hello', 285),\n",
       " ('y’all', 285),\n",
       " ('chia', 284),\n",
       " ('kinda', 284),\n",
       " ('use verified', 284),\n",
       " ('verified code', 284),\n",
       " ('complete', 283),\n",
       " ('job', 283),\n",
       " ('update', 283),\n",
       " ('makeup weightloss', 282),\n",
       " ('sense', 282),\n",
       " ('vs', 282),\n",
       " ('hurt', 281),\n",
       " ('sister', 281),\n",
       " ('star', 280),\n",
       " ('stretch', 280),\n",
       " ('loss', 279),\n",
       " ('food cook', 278),\n",
       " ('cook delicious', 277),\n",
       " ('ginger', 277),\n",
       " ('health healthy', 277),\n",
       " ('nutrient', 277),\n",
       " ('crave', 276),\n",
       " ('dumb', 276),\n",
       " ('greens smoothies', 276),\n",
       " ('gtgt', 276),\n",
       " ('new post', 276),\n",
       " ('result', 276),\n",
       " ('squash', 276),\n",
       " ('competition', 275),\n",
       " ('decision', 275),\n",
       " ('garden', 275),\n",
       " ('interesting', 275),\n",
       " ('muffin', 275),\n",
       " ('nugget', 275),\n",
       " ('haha', 274),\n",
       " ('hold', 274),\n",
       " ('publish', 274),\n",
       " ('oreo', 273),\n",
       " ('supermarket', 273),\n",
       " ('gas', 272),\n",
       " ('junk', 272),\n",
       " ('movement', 272),\n",
       " ('use code', 272),\n",
       " ('customer', 271),\n",
       " ('luck', 271),\n",
       " ('provide', 271),\n",
       " ('cook recipe', 270),\n",
       " ('inside', 270),\n",
       " ('price', 270),\n",
       " ('beyoncé go', 269),\n",
       " ('not believe', 269),\n",
       " ('shoe', 269),\n",
       " ('yogurt', 268),\n",
       " ('coupon', 267),\n",
       " ('rest', 267),\n",
       " ('cuz', 266),\n",
       " ('gain', 266),\n",
       " ('grass', 266),\n",
       " ('message', 266),\n",
       " ('trip', 266),\n",
       " ('worry', 266),\n",
       " ('fall', 265),\n",
       " ('luxury', 265),\n",
       " ('mothersday', 265),\n",
       " ('olive', 265),\n",
       " ('student', 265),\n",
       " ('bath', 264),\n",
       " ('peace', 264),\n",
       " ('’ good', 264),\n",
       " ('jackfruit', 263),\n",
       " ('candle', 262),\n",
       " ('usually', 262),\n",
       " ('account', 261),\n",
       " ('ahead', 261),\n",
       " ('argument', 261),\n",
       " ('base diet', 261),\n",
       " ('delicious cook', 261),\n",
       " ('number', 261),\n",
       " ('detox', 260),\n",
       " ('mexican', 260),\n",
       " ('suppose', 260),\n",
       " ('avoid', 259),\n",
       " ('disease', 259),\n",
       " ('have see', 259),\n",
       " ('if be', 259),\n",
       " ('sleep', 259),\n",
       " ('crispy', 258),\n",
       " ('essential', 258),\n",
       " ('suck', 258),\n",
       " ('sustainable', 258),\n",
       " ('athlete', 257),\n",
       " ('safe', 257),\n",
       " ('table', 257),\n",
       " ('team', 257),\n",
       " ('dick', 256),\n",
       " ('eatclean', 256),\n",
       " ('farming', 256),\n",
       " ('grab', 256),\n",
       " ('lettuce', 256),\n",
       " ('past', 256),\n",
       " ('wake', 256),\n",
       " ('berry', 255),\n",
       " ('bodybuilding muscle', 255),\n",
       " ('documentary', 255),\n",
       " ('page', 255),\n",
       " ('pesto', 255),\n",
       " ('plantbased diet', 255),\n",
       " ('require', 255),\n",
       " ('pound', 254),\n",
       " ('tshirt', 254),\n",
       " ('beat', 253),\n",
       " ('explain', 253),\n",
       " ('good thing', 253),\n",
       " ('ig', 253),\n",
       " ('’ time', 253),\n",
       " ('eating', 252),\n",
       " ('lose weight', 252),\n",
       " ('bakery', 251),\n",
       " ('classic', 251),\n",
       " ('flexible', 251),\n",
       " ('double', 250),\n",
       " ('not care', 250),\n",
       " ('allow', 249),\n",
       " ('deserve', 249),\n",
       " ('discover', 249),\n",
       " ('save vitamins', 249),\n",
       " ('bite', 248),\n",
       " ('calorie', 248),\n",
       " ('im', 248),\n",
       " ('interested', 248),\n",
       " ('lover', 248),\n",
       " ('knit', 247),\n",
       " ('state', 247),\n",
       " ('basically', 246),\n",
       " ('color', 246),\n",
       " ('’ go', 246),\n",
       " ('meatless', 245),\n",
       " ('repost', 245),\n",
       " ('beyoncé say', 244),\n",
       " ('collection', 244),\n",
       " ('frozen', 244),\n",
       " ('naturally', 244),\n",
       " ('parent', 244),\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "sort_word_freq_customized = pickle.load(open('sort_word_freq_customized', 'rb'))\n",
    "sort_word_freq = pickle.load(open('sort_word_freq', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\tjust\n",
      "34\tfood\n",
      "25\teat\n",
      "23\tvegetarian\n",
      "22\tim\n",
      "22\tmeat\n",
      "20\tdiet\n",
      "20\tpeople\n",
      "19\tgoing\n",
      "19\trecipe\n",
      "19\tmake\n",
      "18\tlove\n",
      "18\tgood\n",
      "17\tfree\n",
      "17\tnew\n",
      "15\trecipes\n",
      "15\tanimals\n",
      "15\thealthy\n",
      "15\tknow\n",
      "15\tday\n",
      "14\teating\n",
      "14\tplantbased\n",
      "13\ttime\n",
      "13\tdont\n",
      "13\tcheese\n",
      "13\thealth\n",
      "12\tvegans\n",
      "12\tglutenfree\n",
      "12\tanimal\n",
      "11\ttry\n",
      "11\tneed\n",
      "11\tdon\n",
      "11\tdelicious\n",
      "11\ttoday\n",
      "11\torganic\n",
      "11\treally\n",
      "10\tchocolate\n",
      "10\tbest\n",
      "10\tlife\n",
      "10\tmilk\n",
      "9\tgreat\n",
      "8\tgot\n",
      "8\tvideo\n",
      "8\tveganism\n",
      "8\trt\n",
      "8\tdairy\n",
      "8\traw\n",
      "8\tbeyonc\n",
      "7\tway\n",
      "7\teasy\n",
      "7\tve\n",
      "7\tproducts\n",
      "7\tlol\n",
      "7\tchicken\n",
      "7\tprotein\n",
      "7\tcooking\n",
      "7\tthanks\n",
      "6\tsay\n",
      "6\tpizza\n",
      "6\tthing\n"
     ]
    }
   ],
   "source": [
    "for word, number in sort_word_freq[:60]:\n",
    "    print(str(number//300)+'\\t'+word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = matutils.Sparse2Corpus(counts)\n",
    "\n",
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())\n",
    "\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=20, id2word=id2word, passes=20)\n",
    "\n",
    "lda.print_topics(num_words=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tweets_twograms)\n",
    "corpus = [dictionary.doc2bow(tweet) for tweet in tweets_twograms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=20, id2word=dictionary)\n",
    "lsimodel.show_topics(num_topics=20)  # Showing only the top 5 topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, passes=20, id2word=dictionary)\n",
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
